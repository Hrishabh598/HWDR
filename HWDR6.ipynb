{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAn3VePaVHp-",
        "outputId": "3849218a-3836-45fa-a54a-db2e1cac62d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KXxKMKb5VLU7"
      },
      "outputs": [],
      "source": [
        "#importing the models\n",
        "import torch\n",
        "import numpy as np\n",
        "import mnist\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMHEH2LGVoHR",
        "outputId": "33ce0624-b6d4-4243-e350-d7583daf23b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "#import and create the dataset or preprocess it\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "#As the model used is ANN which take 784 input variables but our test dataset is 2d therefore convert it into single dimension matrix\n",
        "train_images = train_images.reshape(-1,28*28)\n",
        "train_images = train_images/255.0 # as the range is from 0 to 255 so changed it to 0 to 1\n",
        "#similarly for test_images\n",
        "test_images = test_images.reshape(-1,28*28)/255.0\n",
        "\n",
        "#Now the labels\n",
        "train_labels = np.eye(10)[train_labels]\n",
        "test_labels = np.eye(10)[test_labels]\n",
        "\n",
        "# train_images = torch.tensor(train_images)\n",
        "# test_images = torch.tensor(test_images)\n",
        "# train_labels = torch.tensor(train_labels)\n",
        "# test_labels = torch.tensor(test_labels)\n",
        "\n",
        "print(train_labels.shape,test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_images = train_images.to(\"cuda\")"
      ],
      "metadata": {
        "id": "OtK9-7hIKYaF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ovH0cVjvWkP5"
      },
      "outputs": [],
      "source": [
        "#Helping functions\n",
        "def softmax(x):\n",
        "  exp_x = np.exp(x-np.max(x,axis=-1,keepdims=True))\n",
        "  return exp_x/np.sum(exp_x,axis=-1,keepdims=True)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return (1 / (1 + np.exp(-x)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate = 0.1\n",
        "\n",
        "np.random.seed(0)\n",
        "weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "biases_hidden = np.zeros(hidden_size)\n",
        "weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "biases_output = np.zeros(output_size)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(len(train_images)):\n",
        "        # Forward pass\n",
        "        input_layer = train_images[i]\n",
        "        hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n",
        "        hidden_layer_output = sigmoid(hidden_layer_input)  # Sigmoid activation\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
        "        output_layer_output = softmax(output_layer_input)\n",
        "\n",
        "        # Calculate loss (cross-entropy)\n",
        "        loss = -np.sum(train_labels[i] * np.log(output_layer_output))\n",
        "\n",
        "        # Backpropagation\n",
        "        output_error = output_layer_output - train_labels[i]\n",
        "        hidden_error = np.dot(output_error, weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n",
        "        weights_hidden_output -= learning_rate * np.outer(hidden_layer_output, output_error)\n",
        "        biases_output -= learning_rate * output_error\n",
        "        weights_input_hidden -= learning_rate * np.outer(input_layer, hidden_delta)\n",
        "        biases_hidden -= learning_rate * hidden_delta\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeClfOI0N8zB",
        "outputId": "76b50717-54e9-4b87-d990-2db65900d93c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.018713784618766\n",
            "Epoch 2/10, Loss: 0.002085390365429011\n",
            "Epoch 3/10, Loss: 0.013104398914626673\n",
            "Epoch 4/10, Loss: 0.002630742030520313\n",
            "Epoch 5/10, Loss: 0.0020550338996251595\n",
            "Epoch 6/10, Loss: 7.15106892419132e-05\n",
            "Epoch 7/10, Loss: 0.0008135580531129098\n",
            "Epoch 8/10, Loss: 7.729843730715457e-06\n",
            "Epoch 9/10, Loss: 2.8698955353250017e-06\n",
            "Epoch 10/10, Loss: 0.0005724136490047826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "correct = 0\n",
        "for i in range(len(test_images)):\n",
        "    input_layer = test_images[i]\n",
        "    hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n",
        "    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
        "    output_layer_output = softmax(output_layer_input)\n",
        "    prediction = np.argmax(output_layer_output)\n",
        "    if prediction == np.argmax(test_labels[i]):\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(test_images) * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GDlSmEaRItt",
        "outputId": "cb1aa4d4-3818-4637-8973-f2c3dbbc4dbc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 95.82%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}